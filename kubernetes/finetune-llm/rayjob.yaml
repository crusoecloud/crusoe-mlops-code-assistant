apiVersion: ray.io/v1
kind: RayJob
metadata:
  name: lora-train-job
spec:
  entrypoint: "cp -r /home/ray/app/. /tmp/ && bash /tmp/train.sh"

  runtimeEnvYAML: |
    pip:
      - "-r /home/ray/app/requirements.txt"

  shutdownAfterJobFinishes: true
  ttlSecondsAfterFinished: 120

  rayClusterSpec:
    headGroupSpec:
      rayStartParams:
        dashboard-host: "0.0.0.0"
      template:
        spec:
          volumes:
            - name: src
              configMap:
                name: lora-train-src
            - name: mlruns
              emptyDir: {}
          containers:
            - name: head
              image: rayproject/ray-ml:2.33.0.914af0-py311
              workingDir: /tmp
              envFrom:
                - configMapRef:
                    name: lora-train-cfg-default
                - configMapRef:
                    name: lora-train-cfg-local
              env:
                - name: CUDA_VISIBLE_DEVICES
                  value: "0"
                - name: HF_TOKEN
                  valueFrom:
                    secretKeyRef:
                      name: hf-secret
                      key: hf_api_token
              volumeMounts:
                - name: src
                  mountPath: /home/ray/app
                  readOnly: true
                - name: mlruns
                  mountPath: /home/ray/app/mlruns
              resources:
                limits:
                  cpu: "8"
                  memory: 128Gi
                  nvidia.com/gpu: 0
                requests:
                  cpu: "8"
                  memory: 128Gi
                  nvidia.com/gpu: 0

    workerGroupSpecs:
      - groupName: gpu-workers
        rayStartParams: {}
        replicas: 1
        template:
          spec:
            volumes:
              - name: src
                configMap:
                  name: lora-train-src
              - name: mlruns
                emptyDir: {}
            containers:
              - name: worker
                image: rayproject/ray-ml:2.33.0.914af0-py311
                workingDir: /tmp
                envFrom:
                  - configMapRef:
                      name: lora-train-cfg-default
                  - configMapRef:
                      name: lora-train-cfg-local
                env:
                  - name: CUDA_VISIBLE_DEVICES
                    value: "0,1,2,3"
                  - name: HF_TOKEN
                    valueFrom:
                      secretKeyRef:
                        name: hf-secret
                        key: hf_api_token
                volumeMounts:
                  - name: src
                    mountPath: /home/ray/app
                    readOnly: true
                  - name: mlruns
                    mountPath: /home/ray/app/mlruns
                resources:
                  limits:
                    cpu: "8"
                    memory: 128Gi
                    nvidia.com/gpu: 4
                  requests:
                    cpu: "8"
                    memory: 128Gi
                    nvidia.com/gpu: 4

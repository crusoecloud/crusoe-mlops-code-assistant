apiVersion: ray.io/v1alpha1
kind: RayCluster
metadata:
  labels:
    controller-tools.k8s.io: "1.0"
  name: raycluster-llm-finetuning
spec:
  # Uncomment the next line to experiment with autoscaling.
  enableInTreeAutoscaling: true
  # The version of Ray you are using. Make sure all Ray containers are running this version of Ray.
  rayVersion: '2.33.0'
  headGroupSpec:
    serviceType: NodePort
    rayStartParams:
      dashboard-host: '0.0.0.0'
      num-cpus: "0"
      num-gpus: "0"
    template:
      spec:
        containers:
        - name: ray-head
          image: registry.gitlab.com/deepsense.ai/g-crusoe/crusoe-novacode/ray-ml-vllm:0.6.1.post2
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","ray stop"]
          ports:
          - containerPort: 6379
            name: gcs
          - containerPort: 8265
            name: dashboard
          - containerPort: 10001
            name: client
          - containerPort: 44217
            name: as-metrics
          - containerPort: 44227
            name: dash-metrics
          - containerPort: 8000
            name: serve
          resources:
            limits:
              cpu: "4"
              memory: "64Gi"
              # nvidia.com/gpu: "8"
            requests:
              cpu: "4"
              memory: "32Gi"
              # nvidia.com/gpu: "8"
          env:
          - name: RAY_GRAFANA_IFRAME_HOST
            value: http://204.52.26.113:30870
          - name: RAY_GRAFANA_HOST
            value: http://prometheus-grafana.prometheus-system.svc:80
          - name: RAY_PROMETHEUS_HOST
            value: http://prometheus-kube-prometheus-prometheus.prometheus-system.svc:9090
          - name: NUMEXPR_MAX_THREADS
            value: "64"
          - name: HUGGING_FACE_HUB_TOKEN
            valueFrom:
              secretKeyRef:
                name: hf-secret
                key: hf_api_token
          envFrom:
          - configMapRef:
              name: lora-train-cfg-default
              optional: true
          - configMapRef:
              name: lora-train-cfg-local
              optional: true
          volumeMounts:
          - name: lora-train-src
            mountPath: /home/ray/app
        volumes:
        - name: lora-train-src
          configMap:
            name: lora-train-src
            optional: true
            defaultMode: 0755
        imagePullSecrets:
        - name: gitlab-registry
  workerGroupSpecs:
  - replicas: 1
    minReplicas: 1
    maxReplicas: 4
    groupName: gpu-group
    rayStartParams:
      num-gpus: "2"
    template:
      spec:
        containers:
        - name: llm-finetuning
          image: registry.gitlab.com/deepsense.ai/g-crusoe/crusoe-novacode/ray-ml-vllm:0.6.1.post2
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","ray stop"]
          ports:
          - containerPort: 8080
            name: metrics
          resources:
            limits:
              cpu: "64"
              memory: "128Gi"
              nvidia.com/gpu: "2"
            requests:
              cpu: "32"
              memory: "32Gi"
              nvidia.com/gpu: "2"
          env:
          - name: NUMEXPR_MAX_THREADS
            value: "64"
          - name: HUGGING_FACE_HUB_TOKEN
            valueFrom:
              secretKeyRef:
                name: hf-secret
                key: hf_api_token
          envFrom:
            - configMapRef:
                name: lora-train-cfg-default
                optional: true
            - configMapRef:
                name: lora-train-cfg-local
                optional: true
          volumeMounts:
          - name: lora-train-src
            mountPath: /home/ray/app
        volumes:
        - name: lora-train-src
          configMap:
            name: lora-train-src
            optional: true
            defaultMode: 0755
        imagePullSecrets:
        - name: gitlab-registry
